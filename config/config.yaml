---
# Configuration file for running ChIP-seq workflow

# Here is where the reference genomes are specified
reference:
    # name of the genome
    U00096.3:
        # location of the genbanks. If put in the location and format shown
        # below the pipeline will attempt to pull this file from NCBI by
        # accession number. Each genbank MUST have a associated name which
        # is used to name the contig pulled from it.
        genbanks: 
            U00096.3: resources/genbanks/U00096.3.gbk
        # This is the fasta file for each chromosome in the genome
        # If specified location then it is automatically parsed
        # from the genbank.
        fastas:
            - results/alignment/process_genbank/U00096.3/U00096.3.fna
            # but you can also add additional contigs that you may want in
            # the final alignment genome by listing them here
            - test/ecoli_rrnD.fa
        # This allows you to mask regions by replacing them with Ns. Masked
        # regions need to be specified by a bed file
        masked_regions: test/ecoli_rrns.bed

# Options to control preprocessing rules
preprocessing:
    # GENERAL PARADIGM FOR CONTROLLING THINGS FOR ALL SAMPLES OR SPECIFICALLY
    # FOR EACH SAMPLE INDIVIDUALLY
    # Example: 
    # Control the parameter string passed to cutadapt. Here you could change
    # the adaptor sequences for every sample by using 
    # cut_param_string:
    #   value: "my string here"
    # or by sample by using :
    # cut_param_string: 
    #   column: cutadapt_params
    # and specifying the name of the column in the
    # sample sheet that holds the strings you want to for each sample. In this
    # example it would be the column cutadapt_params that holds a string for
    # each sample.
    #
    # This same paradigm is used for all option that have a value or column
    # specifier
    cutadapt_pe:
        cut_param_string:
            value: "-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCA -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGT"
        # some stranded sequence libraries require two cutting steps in this
        # case we needed to remove the last five bases of R1 and the first five
        # bases of R2 after cutting the adaptors off
        cut2_param_string:
            value: "-u -5 -U 5"
    # Control the parameter string from trimmomatic
    trimmomatic_pe:
        trim_param_string:
            value: "LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15"

# Options to control alignment rules
alignment:
    process_genbank:
        # Control what features are parsed from the genbank when pulling out
        # bed files
        features:
            value: "CDS tRNA rRNA ncRNA"
        qual_name: 
            value: "gene locus_tag"

    bowtie2_map:
        # controls how bowtie2 does its alignments
        bowtie2_param_string:
            value: "--end-to-end --very-sensitive --phred33"
        # controls samtools filtering as reads come out of bowtie2. Default
        # is to just convert the sam records into a bam with -b
        samtools_view_param_string:
            value: "-b"

    bowtie2_map_se:
        # controls how bowtie2 does its alignments for single end data
        bowtie2_param_string:
            value: "--end-to-end --very-sensitive --phred33"
        # controls samtools filtering as reads come out of bowtie2. Default
        # is to just convert the sam records into a bam with -b
        samtools_view_param_string:
            value: "-b"


# Options to control genome coverage calculations
coverage_and_norm:

    # what resolution in bp do you want the coverage to be calculated?
    # NET-seq should be single bp resolution
    resolution: 1
    # drop NaNs and Infs from zero coverage in input or extracted
    # Note
    # that bigwigs will not display properly in IGV if they have nans or infs
    dropNaNsandInfs: true


    # revamped spike-in normalization using a model-based approach

    # summarizes values by region
    spike_norm:
        # Can specify different "models" to run by naming them here
        # Model 1 - look at the full coverage for all genes
        all_samples:
            metadata: "pep/test_samples.csv"
            pseudocount: 0.1
            spikecontigs: "U00096.3"
            # only consider the samples that have a genotype A
            filter: 'not input_sample.isnull()'
            # which regions to use? Specifying a file like this has the pipeline
            # parse it from your genbank file given the process genbank
            # parameters above in the alignment section
            regions: "results/alignment/combine_bed/U00096.3/U00096.3.bed"
            # which files to use? This file signature will substitute in
            # a sample name for the %s
            filesignature: "results/coverage_and_norm/deeptools_coverage/%s_%s_raw.bw"
            methods: ["total_frag_sfs", "spike_frag_sfs", "nonspike_frag_sfs", "deseq2_sfs", "deseq2_spike_sfs", "regress_rpm_sfs"]


        all_samples_no_expected:
            metadata: "pep/test_samples.csv"
            pseudocount: 0.1
            spikecontigs: "U00096.3"
            # only consider the samples that have a genotype A
            filter: 'not input_sample.isnull()'
            # which files to use? This file signature will substitute in
            # a sample name for the %s
            filesignature: "results/coverage_and_norm/deeptools_coverage/%s_%s_raw.bw"
            methods: ["regress_rpm_sfs"]

    # rule specific controls
    # Each of these can be specified either as a single value for every sample
    # or as a column in the sample_sheet using column: column_name
    deeptools_coverage:
        bamCoverage_param_string:
            # Want only the 5' end of the read (which is really the
            # 3' end of the NET-seq read)
            column: "bamCoverage_params"
    bwtools_spike_scale:
        # This controls how the spike-in regions are used to scale the
        # data when scaling to a spike-in.
        # Specify the regions to consider for the spike-in here as a bed.
        # Below is a placeholder you would want to put in your own bed here
        fixed_regions:
            value: "results/alignment/process_genbank/U00096.3/U00096.3.bed"

        # What to do with the values in the spike-in sample? This sums the
        # coverage to use as a scaling factor. You could also use mean or
        # median over the regions considered.
        summary_func:
            value: "mean"

    bwtools_median:
        # pseudocount is added before normalizing by the median
        pseudocount:
            value: 1

    # Which samples should be smoothed? Smoothing currently only supported for
    # spike-in and median normalization. This smooths everything.
    # If only want inputs smoothed ('input_sample.isnull()').
    # If want nothing smoothed ('input_sample.isnull() and not
    # input_sample.isnull()')
    smooth_samples:
        filter: 'input_sample.isnull() or not input_sample.isnull()'
    #Control the smoothing type and windowsize
    #Types of smoothing to specify with --operation
    #   - flat_smooth - convolution with a flat kernel (rolling mean)
    #   - gauss_smooth - convolution with a gaussian kernel.
    #       use --gauss_sigma to control the width of the gaussian.
    #   - savgol_smooth - use a Savitzky-Golay filter (see
    #                     https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter)
    #For savgol, use --savgol_poly N to control the order of polynomial. A higher
    #value will do less smoothing. Can't be any higher than the total size of
    #the window
    #
    #Other parameters:
    # wsize - controls the size of half the window in units of resolution. Thus,
    #         a wsize of 50 at resolution of 5 bp is a 
    #         half window size of 50 * 5 = 250
    #         bp. The total window size is then 250*2 + 1 = 500 bp
    # edge - controls how to deal with the boundaries of each contig
    #   'wrap' - wraps the array around the end. Good for circular contigs
    #   'mirror' - mirrors half the window at the edges.
    bwtools_smooth:
        param_string:
            value: "--operation 'gauss_smooth' --wsize 50 --edge 'wrap'"
    bwtools_fixed_subtract:
        # what regions to use as the background when doing a background
        # subtraction. This just uses all genes which is non-sensical.
        # You will want to replace with what you need
        fixed_regions: 
            value: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
    bwtools_fixed_scale:
        # what regions to use as the background when doing a scaling by a
        # fixed set of regions. This just uses all genes which is also
        # non-sensical. You will want to replace with what you need.
        fixed_regions: 
            value: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
    bwtools_query_subtract:
        # What regions to consider for a dynamically chosen background subtraction
        query_regions:
            value: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
        # how many regions to look at?
        number_of_regions:
            value: 10
    bwtools_query_scale:
        # What regions to consider for a max scaling
        query_regions:
            value: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
        # How many regions to look at for max scaling
        number_of_regions:
            value: 10

    bwtools_multicompare:
        # Run these models by doing `snakemake --use-conda --cores
        # N run_bwtools_multicompare`.
        #
        # Allows you to perform operations on multiple bigwigs. This can be one
        # of
        # 1. collapsing multiple bw files into one using a summary statistic
        # 2. comparing two groups of bw files by calculating a summary file for
        #    each group and then a comparison between the summary of groupA and
        #    groupB files.
        # Output File name will be
        # results/coverage_and_norm/bwtools_multicompare/modelname.bw
        # Below is an example of each type
        #
        # Model 1: Take the average of all genotypeA tracks ignoring the input
        # samples
        mean_genotypeA:
            # Filter for genotype A files but exclude the input samples
            filter_groupA: 'genotype == "A" and not input_sample.isnull()'
            # Choose the raw bigwigs as the inputs for each of these samples
            filesignature: "results/coverage_and_norm/deeptools_coverage/%s_raw.bw"
            # Choose an average calculation as the summary statistic. Other 
            # operations include max, min, and median. NaNs and Infs are ignored
            # for the summary calc
            operation_within: "mean"

        # Model 2: Take the average of all genotypeA tracks and subtract the
        # average of all genotypeB tracks. 
        mean_genotypeA_minus_mean_genotypeB:
            # Filter for genotype A files but exclude the input samples
            filter_groupA: 'genotype == "A" and not input_sample.isnull()'
            # Filter for genotype B files but exclude the input samples
            filter_groupB: 'genotype == "B" and not input_sample.isnull()'
            # Choose the raw bigwigs as the inputs for each of these samples
            filesignature: "results/coverage_and_norm/deeptools_coverage/%s_raw.bw"
            # Choose an average calculation as the summary statistic. Other 
            # operations include max, min, and median. NaNs and Infs are ignored
            # for the summary calc
            operation_within: "mean"
            # Choose a subtraction operation for calculations between the
            # summaries of the two groups. Other operations include divide,
            # add, log2ratio, and recipratio.
            operation_btwn: "subtract"

# Options to control quality control
quality_control:
    # what column to group samples by for ChIP-QC output plots?
    group_by: genome
    # control how reads are filter for ALL samples
    bamCoverage_params: " " 
    # Determine sampling parameters for fingerprint plots. These are good
    # defaults for E. coli
    plotFingerprint:
        binsize: 500
        num_samps: 9200
    # Determine bin size for coverage calcs. This controls PCA and correlation
    # as well
    multiBamSummary:
        binsize: 1000
    # Determine sampling parameters for coverage calculations
    plotCoverage:
        num_samps: 1000
    bamPEFragSize:
        bin_dist: 10000



# Options to control peak calling
peak_calling:
    # Can make different models to try out different peak callers or parameters
    macs2_all:
        peak_caller: "macs2"
        # filter out the samples you want to run based on metadata
        filter: 'not input_sample.isnull()'
        # Macs2 runs directly on the bam files for each sample so
        # a filesignature does not need to specified.

        # specify a parameter string used to control macs2
        # -g EFFECTIVE_GENOME_SIZE is
        # automatically determined.
        macs2_param_string: 
            column: macs2_params

# Options to control motif calling
# run with run_motif_calling
motif_calling:
    # Can make different models to try out different motif callers or params
    macs2_all:
        # Which motif caller? Supports meme and streme
        motif_caller: "streme"
        # Which samples to run on?
        filter: 'not input_sample.isnull()'
        # Which file to run on?
        filesignature: "results/peak_calling/macs2_all/macs2/%s_summits.bed"
        # Parameters for the background markov model
        get_markov_param_string:
            value: "-dna -m 2"
        # Parameters for the streme motif caller
        streme_param_string:
            value: "--dna --minw 8 --maxw 30 --nmotifs 2"
        # Parameters controlling how the sequences are pulled from the bed
        get_peak_seqs_param_string:
            value: "--upstream 30 --downstream 30"

    # Same thing but running a different motif finder
    macs2_all_meme:
        motif_caller: "meme"
        filter: 'not input_sample.isnull()'
        filesignature: "results/peak_calling/macs2_all/macs2/%s_summits.bed"
        get_markov_param_string:
            value: "-dna -m 0"
        get_peak_seqs_param_string:
            value: "--upstream 30 --downstream 30"

# Options to control variant calling. I.e. running breseq on the input samples
variant_calling:
    # Which samples do you want to run variant calling on. Typically
    # only the input samples as specified by having no sample name in
    # the "input_sample" column
    filter: "input_sample.isnull() or not input_sample.isnull()"
    # Which reference to compare against. Reference must be defined above
    # in the reference section. Can specify a single value for all samples
    # or a column in the metadata sheet to define a reference for each
    # sample
    reference:
        column: "genome"


# Control for the postprocessing submodule
postprocessing:
    # summarizes values by region
    bwtools_query_stranded:
        # Can specify different "models" to run by naming them here
        # Model 1 - look at the full coverage for all genes
        all_genes_cov:
            # which regions to use? Specifying a file like this has the pipeline
            # parse it from your genbank file given the process genbank
            # parameters above in the alignment section
            regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
            # which files to use? This file signature will substitute in
            # a sample name for the %s
            filesignature: "results/coverage_and_norm/bwtools_compare/%s_%s_median_ratio.bw"
            # how many bp upstream (5') of a feature to include
            upstream: 0
            # how many bp downstream (3') of a feature to include
            downstream: 0
            # what resolution to query data (shouldn't be lower than the
            # resolution of your file
            res : 5
            # How do you want to summarize your data? (identity gives every data
            # point in tidy format)
            summarize: "identity"
            # Calculate spearman correlations between samples? Only make sense
            # for summarize "identity". Try to do this on a small number of
            # samples of the same type
            calc_spearman: true

        all_genes_antisense_cov:
            # which regions to use? Specifying a file like this has the pipeline
            # parse it from your genbank file given the process genbank
            # parameters above in the alignment section
            regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
            # which files to use? This file signature will substitute in
            # a sample name for the %s
            filesignature: "results/coverage_and_norm/bwtools_compare/%s_%s_median_ratio.bw"
            # how many bp upstream (5') of a feature to include
            upstream: 0
            # how many bp downstream (3') of a feature to include
            downstream: 0
            # what resolution to query data (shouldn't be lower than the
            # resolution of your file
            res : 5
            # How do you want to summarize your data? (identity gives every data
            # point in tidy format)
            summarize: "identity"
            antisense: True
            # Calculate spearman correlations between samples? Only make sense
            # for summarize "identity". Try to do this on a small number of
            # samples of the same type
            calc_spearman: true

        # Model 2 - look at the coverage for all genes as a mean summary
        all_genes_mean:
            # which regions to use?
            regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
            # which files to use? Note we can use a different set than Model 1
            filesignature: "results/coverage_and_norm/bwtools_compare/%s_%s_median_ratio_querysub.bw"
            # what resolution to query data (shouldn't be lower than the
            # resolution of your file, think of this as a sampling rate, no 
            # averaging is done over the bins)
            res : 5
            # How do you want to summarize your data? (identity gives every data
            # point in tidy format, single allows for a single number summary)
            summarize: "single"
            # What single number summary do you want (mean, median, max, min,
            # etc.)
            # only defined when summarize is "single"
            summary_func: "mean"
            # what fraction of NaNs can be in a region and still report a value?
            frac_na: 0.20


        all_genes_antisense_mean:
            # which regions to use?
            regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
            # which files to use? Note we can use a different set than Model 1
            filesignature: "results/coverage_and_norm/bwtools_compare/%s_%s_median_ratio_querysub.bw"
            # what resolution to query data (shouldn't be lower than the
            # resolution of your file, think of this as a sampling rate, no 
            # averaging is done over the bins)
            res : 5
            # How do you want to summarize your data? (identity gives every data
            # point in tidy format, single allows for a single number summary)
            summarize: "single"
            # What single number summary do you want (mean, median, max, min,
            # etc.)
            # only defined when summarize is "single"
            summary_func: "mean"
            antisense: True
            # what fraction of NaNs can be in a region and still report a value?
            frac_na: 0.20

        # Model 3 - look at the relative polymerase progression for samples in
        # genotype A
        genotypeA_all_genes_RPP:
            # only consider the samples that have a genotype A. Ensure that they
            # have an associated input sample so that the input samples
            # themselves are not run.
            filter: 'genotype == "A" and not input_sample.isnull()'
            # which regions to use?
            regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
            # which files to use?
            filesignature: "results/coverage_and_norm/bwtools_compare/%s_%s_median_ratio_querysub.bw"
            # what resolution to query data (shouldn't be lower than the
            # resolution of your file
            res : 5
            # How do you want to summarize your data? (identity gives every data
            # point in tidy format, single allows for a single number summary)
            summarize: "single"
            # What single number summary do you want (mean, median, max, min)
            # only defined when summarize is "single"
            summary_func: "RPP"
            # what fraction of NaNs can be in a region and still report a value?
            frac_na: 0.20
        
        # Model 4 - look at the traveling ratio for samples in genotype A
        genotypeA_all_genes_TR:
            # only consider the samples that have a genotype A
            filter: 'genotype == "A" and not input_sample.isnull()'
            # which regions to use?
            regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
            # which files to use?
            filesignature: "results/coverage_and_norm/deeptools_coverage/%s_%s_raw.bw"
            # Here we want to consider 300 bp upstream in our region as well
            upstream: 300
            # what resolution to query data (shouldn't be lower than the
            # resolution of your file
            res : 5
            # How do you want to summarize your data? (identity gives every data
            # point in tidy format, single allows for a single number summary)
            summarize: "single"
            # What single number summary do you want (mean, median, max, min)
            # only defined when summarize is "single"
            summary_func: "TR"
            # what fraction of NaNs can be in a region and still report a value?
            frac_na: 0.20

        # Model 5 - look at the identified beta peak locations for the traveling
        # ratio
        genotypeA_all_genes_TR:
            # only consider the samples that have a genotype A
            filter: 'genotype == "A" and not input_sample.isnull()'
            # which regions to use?
            regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
            # which files to use?
            filesignature: "results/coverage_and_norm/deeptools_coverage/%s_%s_raw.bw"
            # Here we want to consider 300 bp upstream in our region as well
            upstream: 300
            # what resolution to query data (shouldn't be lower than the
            # resolution of your file
            res : 5
            # How do you want to summarize your data? (identity gives every data
            # point in tidy format, single allows for a single number summary)
            summarize: "single"
            # What single number summary do you want (mean, median, max, min)
            # only defined when summarize is "single"
            summary_func: "TR"
            # what fraction of NaNs can be in a region and still report a value?
            frac_na: 0.20
    bwtools_query:
         # Model 6 - look at the average strand ratio at each gene
         all_genes_mean_strand_ratio:
             # which regions to use?
             regions: "results/alignment/process_genbank/U00096.3/U00096.3.bed"
             # which files to use? Note we can use a different set than Model 1
             filesignature: "results/coverage_and_norm/bwtools_compare/%s_log2strandratio.bw"
             # what resolution to query data (shouldn't be lower than the
             # resolution of your file, think of this as a sampling rate, no 
             # averaging is done over the bins)
             res : 5
             # How do you want to summarize your data? (identity gives every data
             # point in tidy format, single allows for a single number summary)
             summarize: "single"
             filter: "input_sample.isnull() or not input_sample.isnull()"
             # What single number summary do you want (mean, median, max, min,
             # etc.)
             # only defined when summarize is "single"
             summary_func: "mean"
             # what fraction of NaNs can be in a region and still report a value?
             frac_na: 0.20

# Control for NETseq submodule
NETseq:
    pause_calling:
        test:
            model_type: "Genomewide"
            NETseq_pause_params: "--method Larson --circular True --filter cov --cov_cutoff 1"
            filter: "seq_method == 'NETseq'"
            wsize: 100

# Control for the modeling submodule
modeling:
    # Specify a specific model you want to run
    by_condition:
        # Which samples?
        filter: "not input_sample.isnull()"
        # How should HTseq count features?
        HTseq_params: "-s reverse -a 0 -i ID -t gene"
        # Which features should be counted?
        regions: "results/alignment/combine_gff/U00096.3/U00096.3.gff"
        # Whats the full model?
        full: "~ genotype"
        # Whats the reduced model?
        reduced: "~ 1"
